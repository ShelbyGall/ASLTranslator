{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d39317-0a32-40c3-8585-818243d8dd8f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf43a2c-36a9-456b-a049-dc3c2f860f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from skimage import io\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "from imageProcessing import mp_detection, formatPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df841f-666f-4c71-822e-d336e3d64d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create array to signify the actions for iterating\n",
    "\n",
    "# actions to be detected by model\n",
    "actions = np.array(['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e1c05-72df-497e-903b-8afc6a412763",
   "metadata": {},
   "source": [
    "# Preprocess Data and create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fa3fd-261c-472e-99e1-3396b460d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create all the path variables\n",
    "\n",
    "# path for exported data (numpy arrays)\n",
    "DATA_PATH = os.path.join('MP_DATA')\n",
    "\n",
    "# the path for the data used to train our model\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'asl_alphabet_train')\n",
    "\n",
    "# the path for the data used to test our model\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'asl_alphabet_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86640dbc-a15c-497d-876d-68b9ef5f6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06d799-8a4b-42a2-88b0-75c48c7b5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "# the number of files we are loading in from our converted numpy dataset to train out model\n",
    "numTrainFiles = 1000\n",
    "for action in actions:\n",
    "    count = 0 \n",
    "    for filename in os.listdir(os.path.join(TRAIN_PATH, action)):\n",
    "        window = []\n",
    "        keypoints = np.load(os.path.join(TRAIN_PATH, action, filename))\n",
    "        window.append(keypoints)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        count += 1\n",
    "        if numTrainFiles == count:\n",
    "            print(f\"Loading Sequences and labels: '{action}' complete\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1fa4d-d083-4aee-9a77-8133cdaab777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of files we are choosing to train the model at the moment\n",
    "# this should match our length of sequences\n",
    "numTrainFiles*(len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06774e3b-a78b-45c7-87c6-b53468c358d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This should be {len(sequences)} if numTrainFiles is {numTrainFiles}: {len(y)}\")\n",
    "print(f\"This should be 29 always: {len(y[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace24b44-4ab2-443b-a4dd-3fcfebaad05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b07dc-0fa9-42e3-b8ba-cb02ec979080",
   "metadata": {},
   "source": [
    "# Splitting our data into training and testing partitions for our model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74f934-3bb1-4d55-937a-ea3599a0a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28830cf6-ebce-4a00-8cb0-1826c10e12ce",
   "metadata": {},
   "source": [
    "# Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e710e9-9fa1-4d3d-ace2-ada51adc168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the console logs to track info while training\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# creating and building the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(1,126)))\n",
    "model.add(LSTM(128, return_sequences=True, activation=\"relu\"))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0429c20-6ed0-4153-98d4-b8762339eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we train the model\n",
    "model.fit(X_train, y_train,epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0efbc-76de-4593-901e-3ffcc2f96a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we save the model to be used later \n",
    "model.save(\"asl_Alphabet_Model_v.0.1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c43fe-d4e7-4862-a5d4-3deee5a2c2dc",
   "metadata": {},
   "source": [
    "# Evaluation using confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc3c5c-95e7-4f67-94b3-d9580676ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e844f25-7d12-487b-94b2-5802f05d0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix representation for checking model accuracy\n",
    "multilabel_confusion_matrix(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee559ef-c501-438c-b1a6-dc6cfd1c5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage accuracy\n",
    "accuracy_score(ytrue,yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
