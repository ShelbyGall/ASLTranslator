{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d1fba3-3e78-4ee8-95ee-bc260dc12e4b",
   "metadata": {},
   "source": [
    "# Converting Our MP_DATA numpy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c0a70-a497-476d-aa5e-a3d333098855",
   "metadata": {},
   "source": [
    "### NOTE: This should only be run by Shelby or people who have the original dataset of jpg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e6409c-4917-4ac0-a2d1-d05185c70970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keyboard\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PredictLetter import mp_detection, formatPoints, draw_styled_landmarks, mp_hands\n",
    "\n",
    "#### create array to signify the actions for iterating\n",
    "\n",
    "# actions to be detected by model\n",
    "actions = np.array(['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])\n",
    "\n",
    "\n",
    "\n",
    "#### create all the path variables\n",
    "\n",
    "# path for exported data (numpy arrays)\n",
    "DATA_PATH = os.path.join('MP_DATA')\n",
    "\n",
    "# the path for the data used to train our model\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'asl_alphabet_train')\n",
    "\n",
    "# the path for the data used to test our model\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'asl_alphabet_test')\n",
    "\n",
    "# the path of the downloaded dataset folder holding all our images to extract the points from\n",
    "DATASET_PATH = 'D:\\\\archive\\\\ASL_Alphabet_Dataset'\n",
    "\n",
    "# path to T folder in jpg dataset\n",
    "ASL_T_PATH = os.path.join(DATASET_PATH, 'asl_alphabet_train', 'T')\n",
    "\n",
    "# path to P folder in jpg dataset\n",
    "ASL_P_PATH = os.path.join(DATASET_PATH, 'asl_alphabet_train', 'P')\n",
    "\n",
    "# path to N folder in jpg dataset\n",
    "ASL_N_PATH = os.path.join(DATASET_PATH, 'asl_alphabet_train', 'N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c0969-aaa7-48b5-8df9-a849d0a82663",
   "metadata": {},
   "source": [
    "### 1. Some of the images in the dataset we were working with are incorrect meaning we will have to fill the image dataset with proper images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f067b-37ba-479d-9f22-7ba2deb4c383",
   "metadata": {},
   "source": [
    "##### Letter: T, N, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766e571-6e2a-4361-8f3c-09c624bcafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "numImagesNeeded = 300\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if keyboard.is_pressed(\"c\"):\n",
    "        cv2.imwrite(os.path.join(ASL_T_PATH, f\"T_T_{numImagesNeeded}.jpg\"), image)\n",
    "        numImagesNeeded = numImagesNeeded - 1\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    if numImagesNeeded == 0:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow('OpenCV Feed', image)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60583e3c-4cc8-434f-9985-7d9b8f74553a",
   "metadata": {},
   "source": [
    "## Setup folders for converted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fc6ba5-d19e-4a98-a555-ee6822808c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create the folders for testing and training in user directory\n",
    "\n",
    "# create the test folder\n",
    "try:\n",
    "    os.makedirs(TEST_PATH)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# create the train folder with all folders for alphabet letters\n",
    "for action in actions:\n",
    "    try: \n",
    "        os.makedirs(os.path.join(TRAIN_PATH, action))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de7463-382b-4a6a-92a4-102e95eafa17",
   "metadata": {},
   "source": [
    "# Extracting points from our image dataset into our converted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6186068-ddea-45ff-92fc-6dbee2cf1200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction starting A\n",
      "Extraction complete A\n",
      "Extraction starting B\n",
      "Extraction complete B\n",
      "Extraction starting C\n",
      "Extraction complete C\n",
      "Extraction starting D\n",
      "Extraction complete D\n",
      "Extraction starting del\n",
      "Extraction complete del\n",
      "Extraction starting E\n",
      "Extraction complete E\n",
      "Extraction starting F\n",
      "Extraction complete F\n",
      "Extraction starting G\n",
      "Extraction complete G\n",
      "Extraction starting H\n",
      "Extraction complete H\n",
      "Extraction starting I\n",
      "Extraction complete I\n",
      "Extraction starting J\n",
      "Extraction complete J\n",
      "Extraction starting K\n",
      "Extraction complete K\n",
      "Extraction starting L\n",
      "Extraction complete L\n",
      "Extraction starting M\n",
      "Extraction complete M\n",
      "Extraction starting N\n",
      "Extraction complete N\n",
      "Extraction starting nothing\n",
      "Extraction complete nothing\n",
      "Extraction starting O\n",
      "Extraction complete O\n",
      "Extraction starting P\n",
      "Extraction complete P\n",
      "Extraction starting Q\n",
      "Extraction complete Q\n",
      "Extraction starting R\n",
      "Extraction complete R\n",
      "Extraction starting S\n",
      "Extraction complete S\n",
      "Extraction starting space\n",
      "Extraction complete space\n",
      "Extraction starting T\n",
      "Extraction complete T\n",
      "Extraction starting U\n",
      "Extraction complete U\n",
      "Extraction starting V\n",
      "Extraction complete V\n",
      "Extraction starting W\n",
      "Extraction complete W\n",
      "Extraction starting X\n",
      "Extraction complete X\n",
      "Extraction starting Y\n",
      "Extraction complete Y\n",
      "Extraction starting Z\n",
      "Extraction complete Z\n"
     ]
    }
   ],
   "source": [
    "with mp_hands.Hands(max_num_hands=2, model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    for action in actions:\n",
    "        CURR_PATH = os.path.join(DATASET_PATH, 'asl_alphabet_train', action)\n",
    "        print(f\"Extraction starting {action}\")\n",
    "\n",
    "        # temporary count variable\n",
    "        # count = 0\n",
    "        # the number of files we want to extract and store\n",
    "        # maxFilesProcessed = 4000\n",
    "        for filename in os.listdir(CURR_PATH):\n",
    "            # if count >= maxFilesProcessed:\n",
    "            #     break\n",
    "            # grab the path of the current image in the dataset to extract points from\n",
    "            IMG_PATH = os.path.join(CURR_PATH, filename)\n",
    "            \n",
    "            # read the image into a variable\n",
    "            img = cv2.imread(IMG_PATH)\n",
    "    \n",
    "            # extract the keypoints from the image\n",
    "            # original image\n",
    "            image, results1 = mp_detection(img, hands)\n",
    "\n",
    "            # flipped image for opposite hand\n",
    "            image2, results2 = mp_detection(cv2.flip(img,1), hands)\n",
    "\n",
    "            # store in array to iterate through\n",
    "            res = [results1, results2]\n",
    "\n",
    "            uniqueEnd = \"orig\"\n",
    "            for results in res:\n",
    "                if results.multi_hand_landmarks and len(results.multi_handedness) == 1:\n",
    "                    # format the points \n",
    "                    points = formatPoints(results)\n",
    "            \n",
    "                    # path to the correct folder to save the points\n",
    "                    SAVE_PATH = os.path.join(TRAIN_PATH, action, filename + uniqueEnd)\n",
    "            \n",
    "                    # save the points to the correct folder\n",
    "                    np.save(SAVE_PATH, points)\n",
    "                    # count += 1\n",
    "                uniqueEnd = \"flip\"\n",
    "            \n",
    "        print(f\"Extraction complete {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ca1035-a80b-4b91-a94a-9bb082000c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our \"nothing\" data folder was messed up due to improper conversion so we are going to fill the nothing folder with empty numpy arrays\n",
    "\n",
    "for num in range(10000):\n",
    "    SAVE_PATH = os.path.join(TRAIN_PATH, \"nothing\", str(num))\n",
    "    np.save(SAVE_PATH, np.zeros(21*3*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc3680-6ff9-4d39-968c-1a757d252dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa1f9d-ff4c-45c1-b3a7-ad52d60bffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
